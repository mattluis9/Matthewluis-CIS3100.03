# -*- coding: utf-8 -*-
"""Project 8

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YdqrCUdDMNyXZiJ4DCeFFZqfNZ-9Bo6J

## premise: study underlying model dynamics
challenge assumptions on sell-factor causality in prices

install

install critical libraries to the underlying os
"""

!pip3 install altair
!pip3 install altair-viewer
!pip3 install -U altair_viewer
!pip3 install statsmodels
!pip3 install imblearn

"""The code below imports all the presaved data within python database's."""

import pandas as pd
import altair as alt
import matplotlib.pyplot as plt #graphics --viz
from imblearn.over_sampling import ADASYN #synthetic minority oversampling
from sklearn.neighbors import KNeighborsClassifier #ML
from sklearn.preprocessing import StandardScaler #---
from statsmodels.tsa.api import VAR #granger causality
from statsmodels.tsa.vector_ar.var_model import VARResults, VARResultsWrapper
from sklearn.model_selection import train_test_split #TTS ,ML
from sklearn.metrics import accuracy_score #error analysis
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report
from scipy import stats

"""retrieve the data...

The code below will grab data from gethub and it will also crease a new panads dataframe and names it mdf.The code is gathering information from the panads dataframe named under 'mdf'. The last line of code, indicates the intention to display but does not have an actual effect to the code.
"""

#load up binary binned pipeline
url_m = 'https://raw.githubusercontent.com/stefanbund/py3100/main/binary_binned_pipeline.csv'
mdf = pd.read_csv(url_m) #make a pandas dataframe
mdf  #matrix dataframe

"""variables associated

The code below retrieves and displays the column names under the dataset,'mdf'. This helps one inspect the feature names inside the dataset.
"""

mdf.columns

"""### reliability of label
correct classification

what is the average "1" trade's value?

The code below calculates the mean of the 'surge_targets_met_pct' inside the dataset 'mdf'. It then sets 'label' to 1. It computes the average value.
"""

mdf[mdf['label']==1]['surge_targets_met_pct'].mean() #.74 or above

"""The code below creates two new dataframes labeled under 'ones' and 'zeros'. It then sets the newly created dataset to different parameters. For example: ones are set to the value of 1 and zeros set the value to 0."""

ones = mdf[mdf['label']==1]  #good trades
zeroes = mdf[mdf['label']==0] #baddies

"""study the underlying dichotomies in your data

NEXT TWO LINES: This code retrieves the number of rows in the dataframe labeled under 'ones' and 'zeroes'. It essentially counts the numbers of rows in 'ones and 'zeros' and displays the number underneath.
"""

ones.shape[0] # finger monkeys

zeroes.shape[0]  #evil monkeys

"""dimensions = features in the data we wish to study, before we classify"""

dimensions = ['precursor_ask_cap_pct_change','precursor_ask_vol_pct_change']

"""The code below, creates a matplot figure. It lists a histogram for two different columns from the dataset 'ones'. The first two lines lables [0] displays a histogram of 'percursor_ask_cap_pct_change'. The last two lines that labels [1] shows all data for the'vol'. plt.show() is the code that shows the figure underneath.  """

fig, axs = plt.subplots(1, 2, figsize=(10, 5))
axs[0].hist(ones['precursor_ask_cap_pct_change'], bins=10)
axs[0].set_title('ONES: Histogram of precursor_ask_cap_pct_change')
axs[1].hist(ones['precursor_ask_vol_pct_change'], bins=10)
axs[1].set_title('ONES: Histogram of precursor_ask_vol_pct_change')
plt.show()

"""### cap vs vol probability density, ONES

NEXT TWO LINES: This code generates a density plot for the'precursor_ask_cap_pct_change' and 'percursor_ask_vol_pct_change'column. It calculates an estimate of the probability distribution of the data. This helps one gather insight into a density function.
"""

ones['precursor_ask_cap_pct_change'].plot.density()  #precursor_ask_vol_pct_change

ones['precursor_ask_vol_pct_change'].plot.density()  #precursor_ask_vol_pct_change

"""### cap vs vol probability density, ZEROES

NEXT TWO LINES: We are still makng a plot density plot, but this time we are gathering the dataframe labled under 'zeroes'
"""

zeroes['precursor_ask_cap_pct_change'].plot.density()  #precursor_ask_vol_pct_change

zeroes['precursor_ask_vol_pct_change'].plot.density()  #precursor_ask_vol_pct_change

"""The code below, creates a matplot figure. It lists a histogram for two different columns from the dataset 'zeroes'. The first two lines lables [0] displays a histogram of 'percursor_ask_cap_pct_change'. The last two lines that labels [1] shows all data for the'vol'. plt.show() is the code that shows the figure underneath.  


"""

fig, axs = plt.subplots(1, 2, figsize=(10, 5))
axs[0].hist(zeroes['precursor_ask_cap_pct_change'], bins=10)
axs[0].set_title('ZEROES: Histogram of precursor_ask_cap_pct_change')
axs[1].hist(zeroes['precursor_ask_vol_pct_change'], bins=10)
axs[1].set_title('ZEROES: Histogram of precursor_ask_vol_pct_change')
plt.show()

"""## Modeling and Prediction Using KNeighbors

1. The code selects a subset of columns from dataset 'm2_pipeline', specified in the 'corr_list'. It then assigns the list to 'm2_pipeline'
2. Then it creates a list of features under 'keepable'.
3. Next it separates the  'label' from the dataframe's features and stores them to new values under 'y' and 'X'
4. The code labled ADASYN is a presaved dataframe that we asked for in earlier code. It creates instances to address class imbalance. It essentially oversamples the minority class.
5. 'train_test_split' splits the dataset into training and testing sets.
'fit_transform' fits the scale on the training data and transforms it
6. 'KNeighborsClassifier' creates a 'k' neighbors classified with speciific parameters
7. Lastly 'fit' fits the 'KNN' is a classifier on the scaled training data.
Main purpose of this whole code is to prepare the data, address different class imbalances with ADASYN, splits the data, and trains a KNN classifier
"""

m2_pipeline = mdf #pd.read_csv("0 Data Processing/binary_binned_pipeline.csv")  #use mdf instead

corr_list = [
'precursor_buy_cap_pct_change', 'precursor_ask_cap_pct_change',
'precursor_bid_vol_pct_change', 'precursor_ask_vol_pct_change','length', 'sum_change', 'surge_targets_met_pct','time', 'label']

m2_pipeline = m2_pipeline[corr_list]
keepable = ['precursor_buy_cap_pct_change',
        'precursor_ask_cap_pct_change',
        'precursor_bid_vol_pct_change',
        'precursor_ask_vol_pct_change',
        'sum_change','length','time']

y = m2_pipeline['label'].values   # y is always a vector, a list of labels
X = m2_pipeline[keepable].values  #x matrix is a list of values/dimensions

X_resampled, y_resampled = ADASYN(random_state=42 ).fit_resample(X, y) #create synthetic classes

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42) #This splits the dataset into training and testing sets

scaler = StandardScaler()  #standardize all numerics
X_train_scaled = scaler.fit_transform(X_resampled) #This standardizes the training data using the fitted scaler

X_test_scaled = scaler.fit_transform(X_test) #This standardizes the test data using the fitted scaler

knn = KNeighborsClassifier(algorithm='auto', n_jobs=1, n_neighbors=3) #creates K-nearest neighbors (KNN) this is a classifier with specific parameters
knn.fit(X_train_scaled, y_resampled)

"""The code below defines the list of column names with corr_list = [].  It then subsets the dataframe 'm2_pipeline' to include the new columns under the list. And lastly 'm2.pipeline.corr()' calculates the matrix for all the selected coluumns. We used a correlation matrix because it shows values closer to -1 or 1. The matrix provides insights into the relationships between different features in the dataset."""

corr_list = [
'precursor_buy_cap_pct_change', 'precursor_ask_cap_pct_change',
'precursor_bid_vol_pct_change', 'precursor_ask_vol_pct_change','length', 'sum_change', 'surge_targets_met_pct','time', 'label']

m2_pipeline = m2_pipeline[corr_list]
m2_pipeline.corr()

"""The code below imports a presaved dataframe in Python. matplotlib.pyplot imports a matplotlib for plotting in the dataframe. 'df= m2.pipeline' creates the new sample, and 'corr_matrix' calculates the specific correlation matrix. The last portion plots the correlation matrix using the function 'matshow()' from the imported Matplotlib. The code all together creates a matplot with different color intensities. The yellow indicates the weaker correlation of each variable with itself. The darker colors are a stronger correlation of each variable."""

import pandas as pd
import matplotlib.pyplot as plt

# create a sample dataframe
df = m2_pipeline

# calculate the correlation matrix
corr_matrix = df.corr()

# plot the correlation matrix
plt.matshow(corr_matrix)
plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)
plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)

plt.show()

#predict
y_pred_knn = knn.predict(X_test_scaled)


#plot decision boundary
# Assuming your KNN model is stored in the variable 'knn'
# plot_decision_boundary(knn, X_test_scaled, y_test)
# plt.show()

# Compute the k-neighborhood graph for your data
graph = knn.kneighbors_graph(X)
graph

"""The code below uses the 'KNN; to predict labels on the 'X_test_scaled". Then it uses 'accuarcy_KNN' to calculate the accuracy of 'KNN'. It does this by comparing the labels in 'y_pred_knn' with the 'y_test'. Then it prints and displays the accuracy of the given numbers.

'labels' obtains labels and uses 'ConfusionMartixDisplay' to create a visualization for the predicted labels.
'zero_division=1" handles the instances with no division by 0 and replaces it with 1.
"""

#display confusion matrix

y_pred_knn = knn.predict(X_test_scaled)

accuracy_knn = accuracy_score(y_test, y_pred_knn)
print(accuracy_knn)

labels_ = m2_pipeline['label'].unique()
print(labels_)
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn, labels=labels_)

print(classification_report(y_test, y_pred_knn ,zero_division=1))

"""### Causality Studies

This just selects the rows from the dataframe 'mdf' where the label is equal to 1 (which are the "good trades". 'keepable' then retries only the columns under its own list. Lastly, 'ones_r" represents a subset of the original dataset under the specilization "good trades".
"""

ones_r = mdf[mdf['label']==1][keepable]  #good trades
ones_r

"""The code below, starts out by defining a function 'test_granger, it then takes 'df and an order 'p'. Then it fits a 'VAR()' model of order 'p' on to the dataframe 'df'.
Then it preforms the granger test. Lastly, it returns a matrix containing p-values of the granger test.

p=7 set the order 'p' to 7, the 'ones =' selects rows from 'mdf' where the label is 1. Then it applies the newly defined test_granger to preform tests under the selected data, and all the data is compiled into 'p_matrix0'

The 'caul_mtrx' renames the rows of 'p_matrix0', to show the variable in every row caused by the corresponding column. Lastly, it sets values less than or equal to 0.01 and all the others are replaced with NaN.
"""

def test_granger(df, p):
    """
    Fits a VAR(p) model on the input df and performs pairwise Granger Causality tests
    """
     # Fit VAR model on first-order differences
    model = VAR(df.diff().dropna())
    results = model.fit(p)
    # Initialize p-value matrix
    p_matrix = pd.DataFrame(index=df.columns, columns=df.columns)
    # Perform pairwise Granger Causality tests
    for caused in df.columns:
        for causing in df.columns:
            if caused != causing:
                test_result = results.test_causality(caused, causing)
                p_value = test_result.pvalue
                p_matrix.loc[caused, causing] = p_value
    # Ensure all columns have float dtypetest_granger
    p_matrix = p_matrix.astype(float)
    return p_matrix

p=7
ones = mdf[mdf['label']==1]  #good trades
p_matrix0 = test_granger(ones_r, p)
caul_mtrx = p_matrix0.rename(index={item: f"{item} caused by" for item in p_matrix0.index})
caul_mtrx.where(caul_mtrx.isna(), caul_mtrx <= 0.01)

"""The code below, slects rows from 'mdf' where the label is 0, it then only keeps the columns under the 'keepable' list.
It then applies the granger test on the dataframe 'zeroes_r' and it then stores the ending results in 'p_matrix1'

Lastly, the 'caul_mtrx is renames to p_matrix1 to show that the variable in each row is caused by the variable in the corresponding column. Similarliy to the last code above, it sets values to 0.01 and replaces others to NAN.
"""

zeroes_r = mdf[mdf['label']==0][keepable]  #bad trades
p_matrix1 = test_granger(zeroes_r, p)
caul_mtrx = p_matrix1.rename(index={item: f"{item} caused by" for item in p_matrix1.index})
caul_mtrx.where(caul_mtrx.isna(), caul_mtrx <= 0.01)